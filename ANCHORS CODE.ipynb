{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "elegant-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "import collections\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import string\n",
    "from io import open\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dressed-pursuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6F8NK8LOB1K98C4'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def id_generator(size=15):\n",
    "    \"\"\"Helper function to generate random div ids. This is useful for embedding\n",
    "    HTML into ipython notebooks.\"\"\"\n",
    "    chars = list(string.ascii_uppercase + string.digits)\n",
    "    return ''.join(np.random.choice(chars, size, replace=True))\n",
    "id_generator(size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "great-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only two funciton insded of from the original Class are needed\n",
    "\n",
    "class AnchorTabularExplainer(object):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            class_names: list of strings\n",
    "            feature_names: list of strings\n",
    "            train_data: used to sample (bootstrap)\n",
    "            categorical_names: map from integer to list of strings, names for each\n",
    "                value of the categorical features. Every feature that is not in\n",
    "                this map will be considered as ordinal or continuous, and thus discretized.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, class_names, feature_names, train_data,\n",
    "                 categorical_names={}, discretizer='quartile', encoder_fn=None):\n",
    "        self.min = {}\n",
    "        self.max = {}\n",
    "        self.disc = collections.namedtuple('random_name2',\n",
    "                                              ['discretize'])(lambda x: x)\n",
    "        self.encoder_fn = lambda x: x\n",
    "        if encoder_fn is not None:\n",
    "            self.encoder_fn = encoder_fn\n",
    "        self.categorical_features = []\n",
    "        self.feature_names = feature_names\n",
    "        self.train = train_data\n",
    "        self.class_names = class_names\n",
    "        self.categorical_names = copy.deepcopy(categorical_names)\n",
    "        if categorical_names:\n",
    "            self.categorical_features = sorted(categorical_names.keys())\n",
    "\n",
    "        if discretizer == 'quartile':\n",
    "            self.disc = lime.lime_tabular.QuartileDiscretizer(train_data,\n",
    "                                                         self.categorical_features,\n",
    "                                                         self.feature_names)\n",
    "        elif discretizer == 'decile':\n",
    "            self.disc = lime.lime_tabular.DecileDiscretizer(train_data,\n",
    "                                                     self.categorical_features,\n",
    "                                                     self.feature_names)\n",
    "        else:\n",
    "            raise ValueError('Discretizer must be quartile or decile')\n",
    "\n",
    "        self.ordinal_features = [x for x in range(len(feature_names)) if x not in self.categorical_features]\n",
    "\n",
    "        self.d_train = self.disc.discretize(self.train)\n",
    "        self.categorical_names.update(self.disc.names)\n",
    "        self.categorical_features += self.ordinal_features\n",
    "\n",
    "        for f in range(train_data.shape[1]):\n",
    "            self.min[f] = np.min(train_data[:, f])\n",
    "            self.max[f] = np.max(train_data[:, f])\n",
    "            \n",
    "    \n",
    "    def get_sample_fn(self, data_row, classifier_fn, desired_label=None):\n",
    "        def predict_fn(x):\n",
    "            return classifier_fn(self.encoder_fn(x))\n",
    "        true_label = desired_label\n",
    "        if true_label is None:\n",
    "            true_label = predict_fn(data_row.reshape(1, -1))[0]\n",
    "        # must map present here to include categorical features (for conditions_eq), and numerical features for geq and leq\n",
    "        mapping = {}\n",
    "        data_row = self.disc.discretize(data_row.reshape(1, -1))[0]\n",
    "        for f in self.categorical_features:\n",
    "            if f in self.ordinal_features:\n",
    "                for v in range(len(self.categorical_names[f])):\n",
    "                    idx = len(mapping)\n",
    "                    if data_row[f] <= v and v != len(self.categorical_names[f]) - 1:\n",
    "                        mapping[idx] = (f, 'leq', v)\n",
    "                        # names[idx] = '%s <= %s' % (self.feature_names[f], v)\n",
    "                    elif data_row[f] > v:\n",
    "                        mapping[idx] = (f, 'geq', v)\n",
    "                        # names[idx] = '%s > %s' % (self.feature_names[f], v)\n",
    "            else:\n",
    "                idx = len(mapping)\n",
    "                mapping[idx] = (f, 'eq', data_row[f])\n",
    "            # names[idx] = '%s = %s' % (\n",
    "            #     self.feature_names[f],\n",
    "            #     self.categorical_names[f][int(data_row[f])])\n",
    "\n",
    "        def sample_fn(present, num_samples, compute_labels=True):\n",
    "            conditions_eq = {}\n",
    "            conditions_leq = {}\n",
    "            conditions_geq = {}\n",
    "            for x in present:\n",
    "                f, op, v = mapping[x]\n",
    "                if op == 'eq':\n",
    "                    conditions_eq[f] = v\n",
    "                if op == 'leq':\n",
    "                    if f not in conditions_leq:\n",
    "                        conditions_leq[f] = v\n",
    "                    conditions_leq[f] = min(conditions_leq[f], v)\n",
    "                if op == 'geq':\n",
    "                    if f not in conditions_geq:\n",
    "                        conditions_geq[f] = v\n",
    "                    conditions_geq[f] = max(conditions_geq[f], v)\n",
    "            # conditions_eq = dict([(x, data_row[x]) for x in present])\n",
    "            raw_data = self.sample_from_train(\n",
    "                conditions_eq, {}, conditions_geq, conditions_leq, num_samples)\n",
    "            d_raw_data = self.disc.discretize(raw_data)\n",
    "            data = np.zeros((num_samples, len(mapping)), int)\n",
    "            for i in mapping:\n",
    "                f, op, v = mapping[i]\n",
    "                if op == 'eq':\n",
    "                    data[:, i] = (d_raw_data[:, f] == data_row[f]).astype(int)\n",
    "                if op == 'leq':\n",
    "                    data[:, i] = (d_raw_data[:, f] <= v).astype(int)\n",
    "                if op == 'geq':\n",
    "                    data[:, i] = (d_raw_data[:, f] > v).astype(int)\n",
    "            # data = (raw_data == data_row).astype(int)\n",
    "            labels = []\n",
    "            if compute_labels:\n",
    "                labels = (predict_fn(raw_data) == true_label).astype(int)\n",
    "            return raw_data, data, labels\n",
    "        return sample_fn, mapping\n",
    "        \n",
    "    \n",
    "    def explain_instance(self, data_row, classifier_fn, threshold=0.95,\n",
    "                          delta=0.1, tau=0.15, batch_size=100,\n",
    "                          max_anchor_size=None,\n",
    "                          desired_label=None,\n",
    "                          beam_size=4, **kwargs):\n",
    "        # It's possible to pass in max_anchor_size\n",
    "        sample_fn, mapping = self.get_sample_fn(\n",
    "            data_row, classifier_fn, desired_label=desired_label)\n",
    "        # return sample_fn, mapping\n",
    "        exp = anchor_base.AnchorBaseBeam.anchor_beam(\n",
    "            sample_fn, delta=delta, epsilon=tau, batch_size=batch_size,\n",
    "            desired_confidence=threshold, max_anchor_size=max_anchor_size,\n",
    "            **kwargs)\n",
    "        self.add_names_to_exp(data_row, exp, mapping)\n",
    "        exp['instance'] = data_row\n",
    "        exp['prediction'] = classifier_fn(self.encoder_fn(data_row.reshape(1, -1)))[0]\n",
    "        explanation = anchor_explanation.AnchorExplanation('tabular', exp, self.as_html)\n",
    "        return explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "secret-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if these two function is sufficient to implement a simple ANCHOR in the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "prepared-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fatf\n",
    "import fatf.utils.data.datasets as fatf_datasets\n",
    "\n",
    "iris_data_dict = fatf_datasets.load_iris()\n",
    "iris_data = iris_data_dict['data']\n",
    "iris_target = iris_data_dict['target']\n",
    "iris_feature_names = iris_data_dict['feature_names'].tolist()\n",
    "iris_target_names = iris_data_dict['target_names'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "national-cigarette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1.0\n",
      "Test 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(iris_data, iris_target, train_size=0.80)\n",
    "blackbox_model = sklearn.ensemble.RandomForestClassifier(n_estimators=10)\n",
    "blackbox_model.fit(train, labels_train)\n",
    "print('Train', sklearn.metrics.accuracy_score(labels_train, blackbox_model.predict(train)))\n",
    "print('Test', sklearn.metrics.accuracy_score(labels_test, blackbox_model.predict(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "continental-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = AnchorTabularExplainer(\n",
    "    iris_target_names,\n",
    "    iris_feature_names,\n",
    "    train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "lonely-people",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  versicolor\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'anchor_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-18a4c6ae51c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Prediction: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblackbox_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblackbox_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-0e5103df5e89>\u001b[0m in \u001b[0;36mexplain_instance\u001b[1;34m(self, data_row, classifier_fn, threshold, delta, tau, batch_size, max_anchor_size, desired_label, beam_size, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m             data_row, classifier_fn, desired_label=desired_label)\n\u001b[0;32m    124\u001b[0m         \u001b[1;31m# return sample_fn, mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         exp = anchor_base.AnchorBaseBeam.anchor_beam(\n\u001b[0m\u001b[0;32m    126\u001b[0m             \u001b[0msample_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mdesired_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_anchor_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_anchor_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'anchor_base' is not defined"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "np.random.seed(1)\n",
    "print('Prediction: ', explainer.class_names[int(blackbox_model.predict(test[idx].reshape(1, -1))[0])])\n",
    "exp = explainer.explain_instance(test[idx], blackbox_model.predict, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-cotton",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
